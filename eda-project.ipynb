{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-14T02:18:54.590210Z","iopub.execute_input":"2022-01-14T02:18:54.590676Z","iopub.status.idle":"2022-01-14T02:18:54.607084Z","shell.execute_reply.started":"2022-01-14T02:18:54.590638Z","shell.execute_reply":"2022-01-14T02:18:54.606364Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# load necessary packages\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:18:54.608683Z","iopub.execute_input":"2022-01-14T02:18:54.609094Z","iopub.status.idle":"2022-01-14T02:18:54.621779Z","shell.execute_reply.started":"2022-01-14T02:18:54.609044Z","shell.execute_reply":"2022-01-14T02:18:54.620844Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# folium for viualizing geospatial data\nimport folium\nfrom folium import plugins\n# the following sklearn packages used to cnvert collection of text documents to a matrix of token counts\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:18:54.623182Z","iopub.execute_input":"2022-01-14T02:18:54.624033Z","iopub.status.idle":"2022-01-14T02:18:55.952413Z","shell.execute_reply.started":"2022-01-14T02:18:54.623990Z","shell.execute_reply":"2022-01-14T02:18:55.951451Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"listings = pd.read_csv ('/kaggle/input/boston/listings.csv');\nreviews = pd.read_csv ('/kaggle/input/boston/reviews.csv');\ncalendar = pd.read_csv ('/kaggle/input/boston/calendar.csv');","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:18:55.954252Z","iopub.execute_input":"2022-01-14T02:18:55.954504Z","iopub.status.idle":"2022-01-14T02:18:57.876575Z","shell.execute_reply.started":"2022-01-14T02:18:55.954473Z","shell.execute_reply":"2022-01-14T02:18:57.875447Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"* **Listings, including full descriptions and average review score.**\n* **Reviews, including unique id for each reviewer and detailed comments.**\n* **Calendar, including listing id and the price and availability for that day.**","metadata":{}},{"cell_type":"markdown","source":"# **Data exploration**","metadata":{}},{"cell_type":"code","source":"listings.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:18:57.877833Z","iopub.execute_input":"2022-01-14T02:18:57.878178Z","iopub.status.idle":"2022-01-14T02:18:57.887194Z","shell.execute_reply.started":"2022-01-14T02:18:57.878136Z","shell.execute_reply":"2022-01-14T02:18:57.886348Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"there are 3585 listings in the data set, with 95 features","metadata":{}},{"cell_type":"markdown","source":"**get percenatage of missing values in listings dataframe****","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\nlistings.isnull().mean().plot.bar(figsize=(40,3));\n# from the above cell, we see that some of the column values are missing\n# here we list the columns with most missing values\nmost_missing_cols = set(listings.columns[listings.isnull().mean() > 0.75])\nmost_missing_cols","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:18:57.888612Z","iopub.execute_input":"2022-01-14T02:18:57.888937Z","iopub.status.idle":"2022-01-14T02:18:59.862078Z","shell.execute_reply.started":"2022-01-14T02:18:57.888907Z","shell.execute_reply":"2022-01-14T02:18:59.861205Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"**lets also see what the other DFs look like****","metadata":{}},{"cell_type":"code","source":"calendar.shape\n## calendar holds avaliablity and price information for each of listings for entire year\ncalendar.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:18:59.863468Z","iopub.execute_input":"2022-01-14T02:18:59.863938Z","iopub.status.idle":"2022-01-14T02:18:59.878928Z","shell.execute_reply.started":"2022-01-14T02:18:59.863896Z","shell.execute_reply":"2022-01-14T02:18:59.878370Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"## reviews hodls the reviews (comments and their names) and reviews dates for different listings\nreviews.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:18:59.879883Z","iopub.execute_input":"2022-01-14T02:18:59.880386Z","iopub.status.idle":"2022-01-14T02:18:59.897974Z","shell.execute_reply.started":"2022-01-14T02:18:59.880347Z","shell.execute_reply":"2022-01-14T02:18:59.897120Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# **How the listing prices are distributed? Which price ranges are the most common?**","metadata":{}},{"cell_type":"markdown","source":"to see the distribution of listing prices, we look at price related column in the listing df. In particular, we look at weekly price column and prepare a bar plot of value counts ","metadata":{}},{"cell_type":"code","source":"weekly_price = listings['weekly_price'].value_counts().rename_axis('price').reset_index(name='counts')\nweekly_price.plot(kind = 'bar', x='price', y='counts', figsize=(90,4))","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:18:59.899690Z","iopub.execute_input":"2022-01-14T02:18:59.900354Z","iopub.status.idle":"2022-01-14T02:19:03.972977Z","shell.execute_reply.started":"2022-01-14T02:18:59.900285Z","shell.execute_reply":"2022-01-14T02:19:03.972401Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"we can see from the above plot that some prices are more frequent and the range of prices is very large.\nto better visualize the distribution of prices, we can draw a histogram of the weekly price distribution.","metadata":{}},{"cell_type":"code","source":"weekly_price['price'] = weekly_price['price'].replace('[\\$,]', '', regex=True).astype(float) # change prices to float type\nweekly_price = weekly_price.sort_values(by=['price'], ascending=True)\nprint('minimum weekly price ($): ', weekly_price['price'].min())\nprint('maximum weekly price ($): ', weekly_price['price'].max())\nweekly_price.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:19:03.974784Z","iopub.execute_input":"2022-01-14T02:19:03.975445Z","iopub.status.idle":"2022-01-14T02:19:03.991240Z","shell.execute_reply.started":"2022-01-14T02:19:03.975410Z","shell.execute_reply":"2022-01-14T02:19:03.990244Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"#  Plot histogram of weekly prices","metadata":{}},{"cell_type":"code","source":"bins=list(range(0, 6400, 50))\n#print(bins)\nax = weekly_price['price'].plot.hist(by = 'price', bins=25, alpha=0.9, figsize=(8,4))\nplt.xticks(fontsize=16)\nplt.yticks(fontsize=16)\nplt.xlabel('Weekly price in $', fontsize = 14)\nplt.ylabel('Frequency', fontsize = 14)\nplt.title(\"Histogram of weekly price in ($)\", fontsize = 16);","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:19:03.992405Z","iopub.execute_input":"2022-01-14T02:19:03.992652Z","iopub.status.idle":"2022-01-14T02:19:04.265546Z","shell.execute_reply.started":"2022-01-14T02:19:03.992625Z","shell.execute_reply":"2022-01-14T02:19:04.264629Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Expensive month?","metadata":{}},{"cell_type":"code","source":"print(calendar.shape)\ncalendar.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:19:04.267021Z","iopub.execute_input":"2022-01-14T02:19:04.267775Z","iopub.status.idle":"2022-01-14T02:19:04.280716Z","shell.execute_reply.started":"2022-01-14T02:19:04.267728Z","shell.execute_reply":"2022-01-14T02:19:04.279911Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#get percenatage of missing values in listings dataframe\n%matplotlib inline\ncalendar.isnull().mean().plot.bar(figsize=(6,4), fontsize = 12);","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:19:04.282251Z","iopub.execute_input":"2022-01-14T02:19:04.282496Z","iopub.status.idle":"2022-01-14T02:19:04.869090Z","shell.execute_reply.started":"2022-01-14T02:19:04.282466Z","shell.execute_reply":"2022-01-14T02:19:04.868276Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":" we can see that about 50% of the listings do not have daily price information for a specific date\n to continue our anlalysis of expensive months, we first drop the rows with missing price information","metadata":{}},{"cell_type":"code","source":"calendar = calendar[calendar['price'].notna()]\ncalendar.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:19:04.870753Z","iopub.execute_input":"2022-01-14T02:19:04.871304Z","iopub.status.idle":"2022-01-14T02:19:05.018756Z","shell.execute_reply.started":"2022-01-14T02:19:04.871260Z","shell.execute_reply":"2022-01-14T02:19:05.017873Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# here we do further preparation of the dataset\n# first extract the month from date column\n# the change the price to float (remove $)\n# then changing availability from t / f to 1 / 0 for ease of analysis\ncalendar['month'] = pd.DatetimeIndex(calendar['date']).month\ncalendar['price'] = calendar['price'].replace('[\\$,]', '', regex=True).astype(float)\ncalendar['available'].replace({'f': 0, 't': 1}, inplace=True)\ncalendar.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:21:03.932944Z","iopub.execute_input":"2022-01-14T02:21:03.933265Z","iopub.status.idle":"2022-01-14T02:21:06.121986Z","shell.execute_reply.started":"2022-01-14T02:21:03.933234Z","shell.execute_reply":"2022-01-14T02:21:06.121048Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# to get the average prices by month, we group the average of the price by month\nprice_by_month = calendar.groupby('month', as_index=False)['price'].mean()\nprice_by_month.plot.bar(x='month', y = 'price', figsize=(12,4));\nplt.xticks(fontsize=16)\nplt.yticks(fontsize=16)\nplt.xlabel('Month', fontsize = 16)\nplt.ylabel('Avg. price', fontsize = 16)\nplt.title(\"Average price per month in ($)\", fontsize = 16);","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:21:37.313625Z","iopub.execute_input":"2022-01-14T02:21:37.314161Z","iopub.status.idle":"2022-01-14T02:21:37.622843Z","shell.execute_reply.started":"2022-01-14T02:21:37.314119Z","shell.execute_reply":"2022-01-14T02:21:37.621888Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print(calendar['price'].min())\nprint(calendar['price'].max())","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:22:04.618676Z","iopub.execute_input":"2022-01-14T02:22:04.618953Z","iopub.status.idle":"2022-01-14T02:22:04.626163Z","shell.execute_reply.started":"2022-01-14T02:22:04.618922Z","shell.execute_reply":"2022-01-14T02:22:04.625147Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"## Plot histogram of prices\nbins=list(range(0, 10, 1700))\n#print(bins)\nax = calendar['price'].plot.hist(by = 'price', bins=25, density=True, alpha=0.9, figsize=(8,4))\nplt.xticks(fontsize=16)\nplt.yticks(fontsize=16)\nplt.xlabel('Price in $', fontsize = 14)\nplt.ylabel('Freq. (probability)', fontsize = 14)\nplt.title(\"Histogram of prices in ($)\", fontsize = 16);","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:22:16.986908Z","iopub.execute_input":"2022-01-14T02:22:16.987404Z","iopub.status.idle":"2022-01-14T02:22:17.320823Z","shell.execute_reply.started":"2022-01-14T02:22:16.987368Z","shell.execute_reply":"2022-01-14T02:22:17.319803Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Conclusions: We can see that month 9 (september) is most expensive, followed closely by octber.It is Mild autumn weather makes touring around on foot a joy.The above histogram of the daily prices also confirm the emprical distribution shown for weekly prices earlier.","metadata":{}},{"cell_type":"markdown","source":"# **Which months are the busiest to visit Boston? Does a busy month also means expensive?**","metadata":{}},{"cell_type":"code","source":"## Here, we make also use of the reviews dataset\nprint(reviews.shape)\nreviews.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:30:01.782571Z","iopub.execute_input":"2022-01-14T02:30:01.782882Z","iopub.status.idle":"2022-01-14T02:30:01.796460Z","shell.execute_reply.started":"2022-01-14T02:30:01.782852Z","shell.execute_reply":"2022-01-14T02:30:01.795502Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#get percenatage of missing values in listings dataframe\n%matplotlib inline\nreviews.isnull().mean().plot.bar(figsize=(6,4), fontsize = 12);","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:30:12.195517Z","iopub.execute_input":"2022-01-14T02:30:12.196200Z","iopub.status.idle":"2022-01-14T02:30:12.442059Z","shell.execute_reply.started":"2022-01-14T02:30:12.196156Z","shell.execute_reply":"2022-01-14T02:30:12.441259Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"## we can see some of the comments are missing\n## to continue our anlalysis, we first drop the rows with missing comments\n## then add month information by extracting from date column\nreviews = reviews[reviews['comments'].notna()]\nreviews['month'] = pd.DatetimeIndex(reviews['date']).month\nreviews.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:30:34.702611Z","iopub.execute_input":"2022-01-14T02:30:34.702940Z","iopub.status.idle":"2022-01-14T02:30:34.761399Z","shell.execute_reply.started":"2022-01-14T02:30:34.702899Z","shell.execute_reply":"2022-01-14T02:30:34.760814Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# number of reviews per month\nreviews_per_month = reviews['month'].value_counts()\n(reviews_per_month/reviews.shape[0]).plot(kind=\"bar\", figsize=(12,4));\nplt.xticks(fontsize=18)\nplt.yticks(fontsize=18)\nplt.title(\"Reviews per month\", fontsize = 16);","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:30:50.271235Z","iopub.execute_input":"2022-01-14T02:30:50.272028Z","iopub.status.idle":"2022-01-14T02:30:50.532350Z","shell.execute_reply.started":"2022-01-14T02:30:50.271981Z","shell.execute_reply":"2022-01-14T02:30:50.531501Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"Conclusions: We can see that August is the busiest month (about 15% of reviews are made in August). Based on the above analysis, september is the most expensive month, followed closely by october. We can see there is not  connection between the most expensive and most busy (indicated by the reviews received) months. in this case the busiest months are in summer.","metadata":{}},{"cell_type":"markdown","source":"# **What is the distribution of the listings in the city borders? are they evenly distribued or concentrated in few neighbourhoods?**","metadata":{}},{"cell_type":"code","source":"# To answer these questions, we look once again to listings dataframe\nlistings.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:33:11.553530Z","iopub.execute_input":"2022-01-14T02:33:11.554033Z","iopub.status.idle":"2022-01-14T02:33:11.593925Z","shell.execute_reply.started":"2022-01-14T02:33:11.553980Z","shell.execute_reply":"2022-01-14T02:33:11.593104Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"## one of the columns with neighbourhood information is the 'neighbourhood_cleansed' column\narea_counts = listings['neighbourhood_cleansed'].value_counts().rename_axis('name').reset_index(name='counts')\narea_counts.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:33:27.137608Z","iopub.execute_input":"2022-01-14T02:33:27.137896Z","iopub.status.idle":"2022-01-14T02:33:27.150293Z","shell.execute_reply.started":"2022-01-14T02:33:27.137867Z","shell.execute_reply":"2022-01-14T02:33:27.149410Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"## To visualize, the most common listings neighbourhood, we can use latitude and longitude columns \nlisting_coordinates = listings[['latitude', 'longitude']]\nlisting_coordinates.values","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:33:41.103106Z","iopub.execute_input":"2022-01-14T02:33:41.103405Z","iopub.status.idle":"2022-01-14T02:33:41.111296Z","shell.execute_reply.started":"2022-01-14T02:33:41.103371Z","shell.execute_reply":"2022-01-14T02:33:41.110521Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"## We can use folium library to plot an interactive heatmap based on the location coordinates we get from listings dataframe\nfrom folium import plugins\nm = folium.Map([42.2826188 , -71.13306793], zoom_start=12) # initialize the map with Boston coordinates\nlocation_array = listing_coordinates.values\n# plot heatmap\nm.add_child(plugins.HeatMap(location_array, radius=20))\nm","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:34:34.771801Z","iopub.execute_input":"2022-01-14T02:34:34.772533Z","iopub.status.idle":"2022-01-14T02:34:34.888130Z","shell.execute_reply.started":"2022-01-14T02:34:34.772480Z","shell.execute_reply":"2022-01-14T02:34:34.887568Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# What can be said aboud the vibe of the neighbourhoods based on reviews?","metadata":{}},{"cell_type":"code","source":"## We continue our analysis using listings df, in particular the neighbourhood_overview and neighbourhood_cleansed columns\ndf = listings[['neighborhood_overview', 'neighbourhood_cleansed']]\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:35:54.971473Z","iopub.execute_input":"2022-01-14T02:35:54.971776Z","iopub.status.idle":"2022-01-14T02:35:54.982961Z","shell.execute_reply.started":"2022-01-14T02:35:54.971745Z","shell.execute_reply":"2022-01-14T02:35:54.982153Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"## We can observe from the cell above that some of the neighborhood_overviews are missing\n## Our anlaysis in the subsequent cells are based on counting the top words/phrases in neighborhood overiews\n## Hence, in the next lines, we are going to drop the rows with missing overviews/reviews\ndf = df.dropna()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:36:09.914961Z","iopub.execute_input":"2022-01-14T02:36:09.915676Z","iopub.status.idle":"2022-01-14T02:36:09.930883Z","shell.execute_reply.started":"2022-01-14T02:36:09.915629Z","shell.execute_reply":"2022-01-14T02:36:09.930300Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"## lets have a look at some random neighbourhood overviews\nprint('first overview:  ', df['neighborhood_overview'].values[0])\nprint('second overview:  ', df['neighborhood_overview'].values[100])\nprint('third overview:  ', df['neighborhood_overview'].values[500])","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:37:00.957919Z","iopub.execute_input":"2022-01-14T02:37:00.958599Z","iopub.status.idle":"2022-01-14T02:37:00.966446Z","shell.execute_reply.started":"2022-01-14T02:37:00.958543Z","shell.execute_reply":"2022-01-14T02:37:00.965357Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"## we prepare a df based on neighbourhood overview descriptons and analyse the common words/phrases\n## the common / frequent words can give us an indication of the vibe of the neighbourhood\noverview = pd.DataFrame(columns = ['description', 'common_words']) # prepare the dataframe\noverview['description'] = df.groupby('neighbourhood_cleansed', as_index=True)['neighborhood_overview'].sum()\noverview['name'] = overview.index\noverview.fillna('', inplace=True)\noverview.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:37:34.544842Z","iopub.execute_input":"2022-01-14T02:37:34.545347Z","iopub.status.idle":"2022-01-14T02:37:34.573022Z","shell.execute_reply.started":"2022-01-14T02:37:34.545280Z","shell.execute_reply":"2022-01-14T02:37:34.572141Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Here we use sklearn countvectorizer library to determine the most common bigrams in neighbourhood descriptions\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ndef get_top_n_bigram(corpus, n=None): \n    '''\n    A function for getting top bigrams of a text\n    It takes a text corpus and a number n as input\n    Returns top n bi-grams of from corpus with frequency excluding stop words\n    '''\n    vec = CountVectorizer(ngram_range=(2, 2), stop_words='english').fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:38:06.909881Z","iopub.execute_input":"2022-01-14T02:38:06.910154Z","iopub.status.idle":"2022-01-14T02:38:06.917927Z","shell.execute_reply.started":"2022-01-14T02:38:06.910126Z","shell.execute_reply":"2022-01-14T02:38:06.916781Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# get top bigrams form neighbourhood_overview descriptions using the above function\nfor i in range(overview.shape[0]):\n    common_words = get_top_n_bigram([overview['description'][i]], 5)\n    for word, freq in common_words:\n        overview['common_words'][i] = overview['common_words'][i] + word + '; '","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:38:18.381403Z","iopub.execute_input":"2022-01-14T02:38:18.381705Z","iopub.status.idle":"2022-01-14T02:38:18.909703Z","shell.execute_reply.started":"2022-01-14T02:38:18.381670Z","shell.execute_reply":"2022-01-14T02:38:18.908751Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"overview.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-14T02:38:27.129406Z","iopub.execute_input":"2022-01-14T02:38:27.129692Z","iopub.status.idle":"2022-01-14T02:38:27.142112Z","shell.execute_reply.started":"2022-01-14T02:38:27.129660Z","shell.execute_reply":"2022-01-14T02:38:27.141213Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}